{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A\n",
    "\n",
    "This notebook explore performance on feature selecting using the pipeline runner to run with different classifier for Task A\n",
    "\n",
    "Preprocessor is a module written to hold function tokenise and extract_features. The module can then be compiled and used for faster execution and clarity in the notebook.\n",
    "\n",
    "PipelineRunner is a module written for this exercise to wrap extract training set, 10 fold cross-validation, and testing in functions for ease of use.\n",
    "\n",
    "First we compile our modules Preprocessor.py and PipelineRunner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import py_compile\n",
    "# py_compile.compile(\"Preprocessor.py\")\n",
    "# py_compile.compile(\"PipelineRunner.py\")\n",
    "\n",
    "import Preprocessor\n",
    "import PipelineRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Attempt: Classify with NaiveBayesClassifier\n",
    "Use nltk.NaiveBayesClassifier and the pipeline function to train and test classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write tokenise, and feature extractor for this task  \n",
    "### Tokeniser: tokenise the given text into a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "tokenise = partial(Preprocessor.tokenise, \\\n",
    "                   more_instances=1, lemmatization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with Feature extractor and  NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>Start 10 fold validation:\n",
      "test range: [0, 765] accuracy: 0.766318537859\n",
      "test range: [766, 1531] accuracy: 0.736292428198\n",
      "test range: [1532, 2297] accuracy: 0.781984334204\n",
      "test range: [2298, 3063] accuracy: 0.783289817232\n",
      "test range: [3064, 3828] accuracy: 0.802614379085\n",
      "test range: [3829, 4593] accuracy: 0.743790849673\n",
      "test range: [4594, 5358] accuracy: 0.721568627451\n",
      "test range: [5359, 6123] accuracy: 0.766013071895\n",
      "test range: [6124, 6888] accuracy: 0.759477124183\n",
      "test range: [6889, 7653] accuracy: 0.801307189542\n",
      "         |    n         p |\n",
      "         |    e    n    o |\n",
      "         |    g    e    s |\n",
      "         |    a    u    i |\n",
      "         |    t    t    t |\n",
      "         |    i    r    i |\n",
      "         |    v    a    v |\n",
      "         |    e    l    e |\n",
      "---------+----------------+\n",
      "negative |<1457>   1 1039 |\n",
      " neutral |   86   <.> 296 |\n",
      "positive |  367    .<4408>|\n",
      "---------+----------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "positive f-measure: 0.838182\n",
      "neutral f-measure: 0.000000\n",
      "negative f-measure: 0.661221\n",
      "Macro f-measure: 0.749701\n",
      "\n",
      ">>>Start applying pipeline to train classifier on whole training set and test on dev set:\n",
      "~~ Training classifier took (sec):\n",
      "0.083996\n",
      "         |   n       p |\n",
      "         |   e   n   o |\n",
      "         |   g   e   s |\n",
      "         |   a   u   i |\n",
      "         |   t   t   t |\n",
      "         |   i   r   i |\n",
      "         |   v   a   v |\n",
      "         |   e   l   e |\n",
      "---------+-------------+\n",
      "negative |<198>  . 144 |\n",
      " neutral |  12  <.> 33 |\n",
      "positive |  39   .<502>|\n",
      "---------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "positive f-measure: 0.822951\n",
      "neutral f-measure: 0.000000\n",
      "negative f-measure: 0.670051\n",
      "Macro f-measure: 0.746501\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "\n",
    "# classifier, tf_cm, tf_gold, tf_result, dev_cm, dev_gold, dev_result = \\\n",
    "#     PipelineRunner.runAllTaskA(tokenise, extract_features, nltk.NaiveBayesClassifier.train)\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('ngram', Preprocessor.extract_ngram()),\n",
    "        ('dict', DictVectorizer()),\n",
    "        ('nb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "pipeline, tf_mfs, tf_gold, tf_result, dev_mfs, dev_gold, dev_result = \\\n",
    "    PipelineRunner.runAllTaskA(pipeline, tokenise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Attempt: Feature Union and  SGDClassifier\n",
    " regularized linear models with stochastic gradient descent (SGD) learning  \n",
    " This classifier turns out to be faster and have comparible results to SVD(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PipelineRunner\n",
    "import Preprocessor\n",
    "\n",
    "reload(PipelineRunner)\n",
    "reload(Preprocessor)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "tokenise = partial(Preprocessor.tokenise, \\\n",
    "                   more_instances=1, lemmatization=True)\n",
    "\n",
    "# load lexicon transformers for faster startup\n",
    "lexicon_liuhu = Preprocessor.lexicon_liuhu()\n",
    "lexicon_emoticon = Preprocessor.lexicon_emoticon()\n",
    "lexicon_NRC_unigram = Preprocessor.lexicon_NRC_unigram()\n",
    "lexicon_NRC_bigram = Preprocessor.lexicon_NRC_bigram()\n",
    "WE_GloVe_Twitter = Preprocessor.WE_GloVe_Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>Start 10 fold validation:\n",
      "test range: [0, 765] accuracy: 0.825065274151\n",
      "test range: [766, 1531] accuracy: 0.828981723238\n",
      "test range: [1532, 2297] accuracy: 0.860313315927\n",
      "test range: [2298, 3063] accuracy: 0.83681462141\n",
      "test range: [3064, 3828] accuracy: 0.870588235294\n",
      "test range: [3829, 4593] accuracy: 0.806535947712\n",
      "test range: [4594, 5358] accuracy: 0.786928104575\n",
      "test range: [5359, 6123] accuracy: 0.822222222222\n",
      "test range: [6124, 6888] accuracy: 0.833986928105\n",
      "test range: [6889, 7653] accuracy: 0.864052287582\n",
      "         |    n         p |\n",
      "         |    e    n    o |\n",
      "         |    g    e    s |\n",
      "         |    a    u    i |\n",
      "         |    t    t    t |\n",
      "         |    i    r    i |\n",
      "         |    v    a    v |\n",
      "         |    e    l    e |\n",
      "---------+----------------+\n",
      "negative |<2009>  16  472 |\n",
      " neutral |  107  <51> 224 |\n",
      "positive |  421   34<4320>|\n",
      "---------+----------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "positive f-measure: 0.882443\n",
      "neutral f-measure: 0.211180\n",
      "negative f-measure: 0.798172\n",
      "Macro f-measure: 0.840308\n",
      "\n",
      ">>>Start applying pipeline to train classifier on whole training set and test on dev set:\n",
      "~~ Training classifier took (sec):\n",
      "9.104012\n",
      "         |   n       p |\n",
      "         |   e   n   o |\n",
      "         |   g   e   s |\n",
      "         |   a   u   i |\n",
      "         |   t   t   t |\n",
      "         |   i   r   i |\n",
      "         |   v   a   v |\n",
      "         |   e   l   e |\n",
      "---------+-------------+\n",
      "negative |<269>  .  73 |\n",
      " neutral |  14  <.> 31 |\n",
      "positive |  45   2<494>|\n",
      "---------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "positive f-measure: 0.867428\n",
      "neutral f-measure: 0.000000\n",
      "negative f-measure: 0.802985\n",
      "Macro f-measure: 0.835206\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# a list of features to be combine in FeatureUnion\n",
    "# different features can be commented out to try different combinations\n",
    "# make sure to also edit weights to match the feature used\n",
    "feature_list = [\n",
    "                ('unigram_tfidf', Pipeline([\n",
    "                    ('ngram', Preprocessor.extract_ngram(ngram_range=(1,1), hashing=True)),\n",
    "                    ('dict', DictVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer())\n",
    "                ])),\n",
    "                ('kskip_bigram_tfidf', Pipeline([\n",
    "                    ('ngram', Preprocessor.extract_kskip_bigram(skip=1, hashing=True)),\n",
    "                    ('dict', DictVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer())\n",
    "                ])),\n",
    "                ('trigram_tfidf', Pipeline([\n",
    "                    ('ngram', Preprocessor.extract_ngram(ngram_range=(3,3), hashing=True)),\n",
    "                    ('dict', DictVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer())\n",
    "                ])),\n",
    "#                   sentiwordnet is slow to run and does not improve much, commented out  \n",
    "                ('lexi_sentiwordnet', Pipeline([\n",
    "                    ('swn', Preprocessor.lexicon_sentiwordnet(feature='score')),\n",
    "                    ('normalise', preprocessing.MinMaxScaler())\n",
    "                ])),\n",
    "                ('lexi_liuhu', Pipeline([\n",
    "                    ('liuhu', lexicon_liuhu),\n",
    "                    ('normalise', preprocessing.Normalizer())\n",
    "                ])),\n",
    "                ('lexi_emoticon', Pipeline([\n",
    "                    ('emoticon', lexicon_emoticon),\n",
    "                    ('normalise', preprocessing.Normalizer())\n",
    "                ])),\n",
    "                ('lexicon_NRC_unigram', Pipeline([\n",
    "                    ('nrc1', lexicon_NRC_unigram),\n",
    "                    ('normalise', preprocessing.Normalizer())\n",
    "                ])),\n",
    "                ('lexicon_NRC_bigram', Pipeline([\n",
    "                    ('bigram', Preprocessor.extract_kskip_bigram(skip=3)),\n",
    "                    ('nrc2', lexicon_NRC_bigram),\n",
    "                    ('normalise', preprocessing.Normalizer())\n",
    "                ])),\n",
    "                ('WE_GloVe', Pipeline([\n",
    "                    ('glove', WE_GloVe_Twitter),\n",
    "                    ('normalise', preprocessing.MinMaxScaler())\n",
    "                ])),\n",
    "                ('related', Pipeline([\n",
    "                    ('trl', Preprocessor.extract_tweeter_related()),\n",
    "                    ('normalise', preprocessing.MinMaxScaler())\n",
    "                ]))\n",
    "               ]\n",
    "\n",
    "# weights of all the feature that match the feature_list. If not given default to 1.0\n",
    "weights = {\n",
    "    'unigram_tfidf':       1.0,\n",
    "    'kskip_bigram_tfidf':  0.4,\n",
    "    'trigram_tfidf':       0.5,\n",
    "    'lexi_sentiwordnet':   0.3,\n",
    "    'lexi_liuhu' :         0.5,\n",
    "    'lexi_emoticon':       0.2,\n",
    "    'lexicon_NRC_unigram': 0.2,\n",
    "    'lexicon_NRC_bigram' : 0.2,\n",
    "    'WE_GloVe'  :          0.4,\n",
    "    'related' :            0.2\n",
    "}\n",
    "\n",
    "clf = ('SGD', SGDClassifier(n_iter=50,average=10))\n",
    "# clf = ('SVC', SVC(kernel='linear'))\n",
    "\n",
    "# combine features and classifier to pipeline\n",
    "pipeline = Pipeline([\n",
    "        ('features', FeatureUnion(\n",
    "                transformer_list = feature_list, \n",
    "                transformer_weights = weights,\n",
    "        )),\n",
    "        clf ])\n",
    "\n",
    "# use our own PipelineRunner to perform testing \n",
    "pipeline, tf_mfs, tf_gold, tf_result, dev_mfs, dev_gold, dev_result = \\\n",
    "    PipelineRunner.runAllTaskA(pipeline, tokenise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation of Macro F-score from 10-fold CV and Dev set\n",
    "The PipelineRunner calculate the Macro f-measure as :  \n",
    "(f-score_for_positive + f-score_for_negative)/2  \n",
    "\n",
    "From the above experiment: we got 2 micro f-score that we can use the value the performance, they are both testing using unseen data, the second score, tested using the dev set might provide a more realistic score because it trained on the entired training set and tested on a unseen dev set. The score is very similar to the score we got from 10-fold cross validation but only slightly lower.\n",
    "\n",
    "We can average the 2 score from the two experiments so that it's easier to compare different settings and classifiers. (notice that this average is NOT the micro f-score from averaging positive and negative class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8377570325287683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tf_mfs + dev_mfs)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classifier on test set and write to result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write result to file\n",
    "test_set = PipelineRunner.getTrainingSetA(PipelineRunner.twitter_test_A_path, tokenise)\n",
    "result = list(pipeline.predict(test_set['tokens']))\n",
    "\n",
    "assert len(result)==len(test_set['tokens'])\n",
    "\n",
    "with open('result/test-A-final.txt', 'w') as resultfile:\n",
    "    lineno = 0\n",
    "    with open(PipelineRunner.twitter_test_A_path) as tsvfile:\n",
    "            for aline in tsvfile:\n",
    "                line = aline.strip().split('\\t')\n",
    "                resultfile.write('\\t'.join(line[0:4]+[result[lineno]])+'\\n')\n",
    "                lineno += 1\n",
    "    assert len(result)==lineno            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
